{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e6bb07",
   "metadata": {},
   "source": [
    "# CoinCap API ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27bb15-1e70-441c-962e-08f8e9d25ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51058c41-350d-412e-86fc-ac9a5c6dcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinCap_monitor:\n",
    "    def __init__(self):\n",
    "        self.__host = os.environ['API_URI']\n",
    "        self.__key = os.environ['API_KEY']\n",
    "        self.__pg_uri = os.environ['DB_URI']\n",
    "        self.__pg_port = os.environ['DB_PORT']\n",
    "        self.__pg_user = os.environ['POSTGRES_USER']\n",
    "        self.__pg_password = os.environ['POSTGRES_PASSWORD']\n",
    "        self.__pg_database = os.environ['POSTGRES_DB']\n",
    "\n",
    "\n",
    "    def get_endpoint(self, endpoint:str) -> bool:\n",
    "            \n",
    "        try:\n",
    "            if endpoint!='/markets' and endpoint!='/assets' and endpoint!='/exchanges':\n",
    "                raise Exception('The endpoint is not valid.')\n",
    "\n",
    "            offset = 0\n",
    "            response_list=[]\n",
    "            if endpoint == '/markets':\n",
    "                while True:\n",
    "                    params = {\"key\": self.__key, \"limit\":2000, 'offset':offset}\n",
    "                    response = requests.get(self.__host + endpoint, params=params)\n",
    "                    response.raise_for_status()\n",
    "                    response_list += response.json().get(\"data\")\n",
    "                    if len(response.json().get(\"data\")) < 2000:\n",
    "                        break\n",
    "                    offset+=2000\n",
    "            else:\n",
    "                params = {\"key\": self.__key}\n",
    "                response = requests.get(self.__host + endpoint, params=params)\n",
    "                response.raise_for_status()\n",
    "                response_list = response.json().get(\"data\")\n",
    "            data_df = pd.DataFrame(response_list)\n",
    "            \n",
    "            if endpoint == '/assets':\n",
    "                self.raw_assets = data_df\n",
    "            elif endpoint == '/exchanges':\n",
    "                self.raw_exchanges = data_df\n",
    "            elif endpoint == '/markets':\n",
    "                self.raw_markets = data_df\n",
    "\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "            return False\n",
    "\n",
    "    def write_lake(self, layer:str, table:str, df:pd.DataFrame, now:datetime) -> bool:\n",
    "        try:\n",
    "            if layer!='raw' and layer!='trusted' and layer!='refined':\n",
    "                raise Exception('The layer is not valid.')\n",
    "\n",
    "            if table!='assets' and table!='exchanges' and table!='markets':\n",
    "                raise Exception('The table is not valid.')\n",
    "            \n",
    "            date_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            path = f'/home/jovyan/data/{layer}/{table}'\n",
    "            file_name = f'{table}-{date_str}.parquet'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            df.to_parquet(path=f'{path}/{file_name}', index=False)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "            return False\n",
    "\n",
    "    def refine_assets(self, now:datetime) -> bool:\n",
    "        try:\n",
    "            df_assets = self.raw_assets.copy()\n",
    "            df_assets = df_assets[['id', 'rank', 'symbol', 'name', 'supply',\n",
    "                       'maxSupply', 'marketCapUsd', 'volumeUsd24Hr', 'priceUsd']]\n",
    "            df_assets.drop_duplicates(subset=['id'], keep='last', inplace=True)\n",
    "            df_assets = df_assets.astype({'rank': 'int64',\n",
    "                                          'supply': 'float64',\n",
    "                                          'maxSupply': 'float64',\n",
    "                                          'marketCapUsd': 'float64',\n",
    "                                          'volumeUsd24Hr': 'float64',\n",
    "                                          'priceUsd': 'float64'})\n",
    "            df_assets['extracted'] = now\n",
    "\n",
    "            self.refined_assets = df_assets\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "            return False\n",
    "\n",
    "    def refine_exchanges(self, now:datetime) -> bool:\n",
    "        try:\n",
    "            df_exchanges = self.raw_exchanges.copy()\n",
    "            df_exchanges = df_exchanges[df_exchanges.tradingPairs!='0']\n",
    "            df_exchanges = df_exchanges[['exchangeId', 'name', 'rank', 'percentTotalVolume',\n",
    "                                         'volumeUsd', 'exchangeUrl', 'updated']]\n",
    "            df_exchanges.drop_duplicates(subset=['exchangeId'], keep='last', inplace=True)\n",
    "            df_exchanges = df_exchanges.astype({ 'rank': 'int64',\n",
    "                                                 'percentTotalVolume': 'float64',\n",
    "                                                 'volumeUsd': 'float64',\n",
    "                                                 'updated': 'datetime64[us]'\n",
    "            })\n",
    "            df_exchanges.dropna(subset=['percentTotalVolume', 'volumeUsd'])\n",
    "            \n",
    "            df_exchanges['extracted'] = now\n",
    "\n",
    "            self.refined_exchanges = df_exchanges\n",
    "\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "            return False\n",
    "\n",
    "    def refine_markets(self, now:datetime) -> bool:\n",
    "        try:\n",
    "            df_markets = self.raw_markets.copy()\n",
    "            df_markets = df_markets[['exchangeId', 'baseId', 'quoteId', 'priceUsd', 'updated']]\n",
    "            df_markets.drop_duplicates(subset=['exchangeId', 'baseId', 'quoteId'], keep='last', inplace=True)\n",
    "            df_markets = df_markets.astype({ 'priceUsd': 'float64',\n",
    "                                             'updated': 'datetime64[us]'\n",
    "            })\n",
    "            \n",
    "            filter_exchange = df_markets['exchangeId'].isin(self.refined_exchanges['exchangeId'])\n",
    "            filter_quote = df_markets['quoteId'].isin(self.refined_assets['id'])\n",
    "            filter_base = df_markets['baseId'].isin(self.refined_assets['id'])\n",
    "            \n",
    "            df_markets = df_markets[filter_exchange & filter_quote & filter_base]\n",
    "            \n",
    "            df_markets['extracted'] = now\n",
    "\n",
    "            self.refined_markets = df_markets\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    def create_tables(self):\n",
    "        try:\n",
    "            asset_ddl_path = \"./assets_ddl.sql\"\n",
    "            exchanges_ddl_path = \"./exchanges_ddl.sql\"\n",
    "            markets_ddl_path = \"./markets_ddl.sql\"\n",
    "            engine = create_engine(f'postgresql://{self.__pg_user}:{self.__pg_password}@{self.__pg_uri}:{self.__pg_port}/{self.__pg_database}')\n",
    "            conn = engine.connect()\n",
    "            for filepath in [asset_ddl_path, exchanges_ddl_path, markets_ddl_path]:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    sql = file.read()\n",
    "                    conn.execute(text(sql))\n",
    "                    conn.commit()\n",
    "                    \n",
    "        except Exception as e:\n",
    "             print(f\"something unexpected happened: {e}\")\n",
    "\n",
    "    def insert_data_to_pg(self, table_name:str, df:pd.DataFrame) ->bool:\n",
    "        try:\n",
    "            engine = create_engine(f'postgresql://{self.__pg_user}:{self.__pg_password}@{self.__pg_uri}:{self.__pg_port}/{self.__pg_database}')\n",
    "            df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"something unexpected happened: {e}\")\n",
    "        \n",
    "\n",
    "    def start_monitor(self):\n",
    "\n",
    "        self.create_tables()\n",
    "        while True:\n",
    "            now = datetime.now()\n",
    "            self.get_endpoint('/assets')\n",
    "            self.write_lake('raw', 'assets', self.raw_assets, now)\n",
    "            \n",
    "            self.get_endpoint('/exchanges')\n",
    "            self.write_lake('raw', 'exchanges', self.raw_exchanges, now)\n",
    "            \n",
    "            self.get_endpoint('/markets')\n",
    "            self.write_lake('raw', 'markets', self.raw_markets, now)\n",
    "    \n",
    "            self.refine_assets(now)\n",
    "            self.write_lake('refined', 'assets', self.refined_assets, now)\n",
    "    \n",
    "            self.refine_exchanges(now)\n",
    "            self.write_lake('refined', 'exchanges', self.refined_exchanges, now)\n",
    "    \n",
    "            self.refine_markets(now)\n",
    "            self.write_lake('refined', 'markets', self.refined_markets, now)\n",
    "    \n",
    "            self.insert_data_to_pg('Assets', self.refined_assets)\n",
    "            self.insert_data_to_pg('Exchanges', self.refined_exchanges)\n",
    "            self.insert_data_to_pg('Markets', self.refined_markets)\n",
    "\n",
    "            time.sleep(60)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e600d8-1439-481e-9b88-300936c430de",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = CoinCap_monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703aa06a-c7a2-49ec-97c4-d485d1d77b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monitor.start_monitor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
